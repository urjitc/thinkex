import { gateway } from "ai";
import { streamText, convertToModelMessages, stepCountIs, wrapLanguageModel, tool } from "ai";
import { devToolsMiddleware } from "@ai-sdk/devtools";
import { PostHog } from "posthog-node";
import { withTracing } from "@posthog/ai";
import type { UIMessage } from "ai";
import { logger } from "@/lib/utils/logger";
import { auth } from "@/lib/auth";
import { headers } from "next/headers";
import { createChatTools } from "@/lib/ai/tools";
import type { GatewayProviderOptions } from "@ai-sdk/gateway";

// Regex patterns as constants (compiled once, reused for all requests)
const URL_CONTEXT_REGEX = /\[URL_CONTEXT:(.+?)\]/g;
const DIRECT_URL_REGEX = /https?:\/\/[^\s]+/g;
const FILE_URL_REGEX = /\[FILE_URL:([^|]+)\|mediaType:([^|]*)\|filename:([^\]]*)\]/g;

/**
 * Extract workspaceId from system context or request body
 */
function extractWorkspaceId(body: any): string | null {
  if (body.workspaceId) {
    return body.workspaceId;
  }

  const system = body.system || "";
  const workspaceIdMatch = system.match(/Workspace ID: ([a-f0-9-]{36})/);
  if (workspaceIdMatch) {
    return workspaceIdMatch[1];
  }

  return null;
}

/**
 * Process messages in a single pass: extract file URLs, URL context URLs, and clean markers
 * This combines 3 separate iterations into 1 for better performance
 */
function processMessages(messages: any[]): {
  fileUrls: string[];
  urlContextUrls: string[];
  cleanedMessages: any[];
} {
  const fileUrls: string[] = [];
  const urlContextUrlsSet = new Set<string>();

  const cleanedMessages = messages.map((message) => {
    if (message.content && Array.isArray(message.content)) {
      const updatedContent = message.content.map((part: any) => {
        if (part.type === "text" && typeof part.text === "string") {
          const text = part.text;

          // Extract file URLs (create new regex instance to avoid state issues with global flag)
          let match;
          const fileUrlRegexLocal = new RegExp(FILE_URL_REGEX.source, FILE_URL_REGEX.flags);
          while ((match = fileUrlRegexLocal.exec(text)) !== null) {
            fileUrls.push(match[1]);
          }

          // Extract URL context URLs (use Set for O(1) lookups)
          const urlContextRegexLocal = new RegExp(URL_CONTEXT_REGEX.source, URL_CONTEXT_REGEX.flags);
          const urlContextMatches = text.matchAll(urlContextRegexLocal);
          for (const urlMatch of urlContextMatches) {
            const url = urlMatch[1];
            if (url) urlContextUrlsSet.add(url);
          }

          // Extract direct URLs
          const directUrlRegexLocal = new RegExp(DIRECT_URL_REGEX.source, DIRECT_URL_REGEX.flags);
          const directUrlMatches = text.matchAll(directUrlRegexLocal);
          for (const directMatch of directUrlMatches) {
            const url = directMatch[0];
            if (url) urlContextUrlsSet.add(url);
          }

          // Clean URL_CONTEXT markers (create new instance to avoid global regex state issues)
          const urlContextReplaceRegex = new RegExp(URL_CONTEXT_REGEX.source, URL_CONTEXT_REGEX.flags);
          const updatedText = text.replace(urlContextReplaceRegex, (_match: string, url: string) => {
            return url;
          });

          return { ...part, text: updatedText };
        }
        return part;
      });
      return { ...message, content: updatedContent } as typeof message;
    }
    return message;
  });

  return {
    fileUrls,
    urlContextUrls: Array.from(urlContextUrlsSet),
    cleanedMessages,
  };
}

/**
 * Selected cards context is now formatted on the client side and sent directly.
 * This eliminates the need for server-side database fetch.
 * If selectedCardsContext is provided, use it; otherwise return empty string.
 */
function getSelectedCardsContext(body: any): string {
  // Client now sends pre-formatted context string
  return body.selectedCardsContext || "";
}

// Regex to detect createFrom auto-generated prompts
const CREATE_FROM_REGEX = /^Update the preexisting contents of this workspace to be about (.+)\. Only add one quality YouTube video\.$/;

/**
 * Detect if the first user message is a createFrom auto-generated prompt
 * and return additional system instructions for better workspace curation
 */
function getCreateFromSystemPrompt(messages: any[]): string | null {
  // Find the first user message
  const firstUserMessage = messages.find((m) => m.role === "user");
  if (!firstUserMessage) return null;

  // Extract text content from the message
  let textContent = "";
  if (typeof firstUserMessage.content === "string") {
    textContent = firstUserMessage.content;
  } else if (Array.isArray(firstUserMessage.content)) {
    const textPart = firstUserMessage.content.find((p: any) => p.type === "text");
    if (textPart?.text) textContent = textPart.text;
  }

  // Check if it matches the createFrom pattern
  const match = textContent.match(CREATE_FROM_REGEX);
  if (!match) return null;

  const topic = match[1];

  return `
CREATE-FROM WORKSPACE INITIALIZATION MODE:
This is an automatic workspace initialization request. The user wants to transform this workspace into a curated learning/research space about: "${topic}"

CRITICAL INSTRUCTIONS FOR WORKSPACE CURATION:
1. **For each of the existing workspace items** update the title and content to be about the topic:
   - Use \`updateNote\` tool for notes
   - Use \`updateFlashcards\` tool for flashcard sets
   - Use \`updateQuiz\` tool for quizzes
2. **Be thorough but focused** - Provide a solid foundation for understanding the topic without being overwhelming.
3. **Do NOT ask the user questions** - This is an automated initialization, proceed directly with updating the workspace.

QUALITY GUIDELINES FOR CONTENT:
- Start with a clear introduction/overview of the topic
- Include key concepts, definitions, or components
- Add practical examples or use cases if relevant
- For flashcards: create exactly 5 meaningful question/answer pairs covering key concepts
- For quizzes: create challenging but fair questions that test understanding

QUALITY GUIDELINES FOR THE YOUTUBE VIDEO:
- Search with specific, relevant terms for the topic
- Prefer videos that are educational/explanatory
- Look for high view counts and reputable channels as quality signals
`;
}

/**
 * Build the enhanced system prompt with guidelines and detection hints
 * Uses array join for better performance than string concatenation
 */
function buildSystemPrompt(baseSystem: string, fileUrls: string[], urlContextUrls: string[]): string {
  const parts: string[] = [baseSystem];

  // Add web search decision-making guidelines
  parts.push(`

WEB SEARCH GUIDELINES:
Use webSearch when: temporal cues ("today", "latest", "current"), real-time data (scores, stocks, weather), fact verification, niche/recent info.
Use internal knowledge for: creative writing, coding, general concepts, summarizing provided content.
If uncertain about accuracy, prefer to search.

YOUTUBE: If user says "add a video" without a topic, infer from workspace context. Don't ask - just search.

SOURCE EXTRACTION (CRITICAL):
When creating/updating notes with research:
1. Call webSearch first
2. Extract sources from groundingMetadata.groundingChunks[].web.{uri, title}
3. Pass sources to createNote/updateNote - NEVER put citations in note content itself

Rules:
- Use chunk.web.uri exactly as provided (even redirect URLs)
- Never make up or hallucinate URLs
- Include article dates in responses when available`);


  // Add file detection hint if file URLs are present
  if (fileUrls.length > 0) {
    parts.push(`\n\nFILE DETECTION: The user's message contains ${fileUrls.length} file(s). You MUST call the processFiles tool with these URLs to analyze them: ${fileUrls.join(', ')}`);
  }

  // Add URL detection hint if URLs are present
  if (urlContextUrls.length > 0) {
    parts.push(`\n\nURL DETECTION: The user's message contains ${urlContextUrls.length} URL(s): ${urlContextUrls.join(', ')}. You should call the processUrls tool with these URLs to analyze them.`);
  }

  return parts.join('');
}

export async function POST(req: Request) {
  let workspaceId: string | null = null;
  let activeFolderId: string | undefined;

  // Check for API key early (Standardizing on Google Key for now if not using OIDC)
  // With Gateway, you can check for other keys too, or rely on Gateway's auth
  if (!process.env.GOOGLE_GENERATIVE_AI_API_KEY && !process.env.AI_GATEWAY_API_KEY) {
    // Optional: make this check more robust or permissive if using OIDC
  }

  try {
    // FIX: Parallelize headers() and req.json() to eliminate waterfall
    const [headersObj, body] = await Promise.all([
      headers(),
      req.json()
    ]);

    // Get authenticated user ID
    const session = await auth.api.getSession({ headers: headersObj });
    const userId = session?.user?.id || null;

    const { messages = [] }: { messages?: UIMessage[] } = body;
    const system = body.system || "";
    workspaceId = extractWorkspaceId(body);
    activeFolderId = body.activeFolderId;

    // Convert messages
    let convertedMessages;
    try {
      convertedMessages = await convertToModelMessages(messages);
    } catch (convertError) {
      logger.error("‚ùå [CHAT-API] convertToModelMessages FAILED:", {
        error: convertError instanceof Error ? convertError.message : String(convertError),
        stack: convertError instanceof Error ? convertError.stack : undefined,
      });
      throw convertError;
    }

    // Process messages in single pass: extract URLs/files and clean markers
    const { fileUrls, urlContextUrls, cleanedMessages } = processMessages(convertedMessages);

    // Get pre-formatted selected cards context from client (no DB fetch needed)
    const selectedCardsContext = getSelectedCardsContext(body);

    // Get model ID and ensure it has the correct prefix for Gateway
    let modelId = body.modelId || "moonshotai/kimi-k2-0905";

    // Auto-prefix with google/ if it looks like a gemini model and lacks prefix
    // This allows existing client code to work without changes
    if (modelId.startsWith("gemini-") && !modelId.startsWith("google/")) {
      modelId = `google/${modelId}`;
    }

    // Build system prompt with all context parts (using array join for efficiency)
    // Note: The base `system` from client already includes AI assistant identity from formatWorkspaceContext
    const systemPromptParts: string[] = [
      buildSystemPrompt(system, fileUrls, urlContextUrls)
    ];

    // Inject createFrom workspace initialization prompt if detected
    const createFromPrompt = getCreateFromSystemPrompt(cleanedMessages);
    if (createFromPrompt) {
      systemPromptParts.push(`\n\n${createFromPrompt}`);
    }

    // Inject selected cards context if available
    if (selectedCardsContext) {
      systemPromptParts.push(`\n\n${selectedCardsContext}`);
    }

    // Inject reply context if available
    const replySelections = body.replySelections || [];
    if (replySelections.length > 0) {
      const replyContext = replySelections
        .map((sel: { text: string }) => `> ${sel.text}`)
        .join("\n");
      systemPromptParts.push(`\n\nREPLY CONTEXT:\nThe user is replying specifically to these parts of the previous message:\n${replyContext}`);
    }

    const finalSystemPrompt = systemPromptParts.join('');

    // Initialize PostHog client
    const posthogClient = new PostHog(process.env.POSTHOG_API_KEY || "disabled", {
      host: process.env.POSTHOG_HOST || "https://us.i.posthog.com",
      disabled: !process.env.POSTHOG_API_KEY,
    });

    // Use AI Gateway
    const model = wrapLanguageModel({
      model: withTracing(gateway(modelId) as any, posthogClient, {
        posthogDistinctId: userId || "anonymous",
        posthogProperties: {
          workspaceId,
          activeFolderId,
          modelId,
        },
      }),
      middleware: process.env.NODE_ENV === 'development' ? devToolsMiddleware() : [],
    });

    // Create tools using the modular factory
    const tools = createChatTools({
      workspaceId,
      userId,
      activeFolderId,
      clientTools: body.tools,
    });

    // Stream the response
    logger.debug("üîç [CHAT-API] Final cleanedMessages before streamText:", {
      count: cleanedMessages.length,
      modelId
    });

    // Configure Google Thinking capabilities
    const googleConfig: any = {
      grounding: {
        googleSearchRetrieval: {
          dynamicRetrievalConfig: {
            mode: 'MODE_DYNAMIC',
          },
        },
      },
      thinkingConfig: {
        includeThoughts: false,
      },
    };

    // Explicitly disable thinking tokens for Gemini 2.5
    if (modelId.includes("gemini-2.5")) {
      googleConfig.thinkingConfig.thinkingBudget = 0;
    }

    // Prepare provider options
    // The Gateway passes these through to the specific provider
    let providerOptions: any = {
      gateway: {
        // Example: route to google if you want to enforce it, though prefix handles it
        // order: ['google'], 
      } satisfies GatewayProviderOptions,
      google: googleConfig,
    };

    const result = streamText({
      model: model,
      temperature: 1.0,
      system: finalSystemPrompt,
      messages: cleanedMessages,
      stopWhen: stepCountIs(25),
      tools,
      providerOptions,
      onFinish: ({ usage, finishReason }) => {
        const usageInfo = {
          inputTokens: usage?.inputTokens,
          outputTokens: usage?.outputTokens,
          totalTokens: usage?.totalTokens,
          cachedInputTokens: usage?.cachedInputTokens, // Standard property
          reasoningTokens: usage?.reasoningTokens,
          // Note: Extended provider-specific properties might not be available consistently via Gateway
          finishReason,
        };

        logger.info("üìä [CHAT-API] Final Token Usage:", usageInfo);
      },
      onStepFinish: (result) => {
        // stepType exists in runtime but may not be in type definitions
        const stepResult = result as typeof result & { stepType?: "initial" | "continue" | "tool-result" };
        const { stepType, usage, finishReason } = stepResult;

        if (usage) {
          const stepUsageInfo = {
            stepType: stepType || 'unknown',
            inputTokens: usage?.inputTokens,
            outputTokens: usage?.outputTokens,
            totalTokens: usage?.totalTokens,
            cachedInputTokens: usage?.cachedInputTokens, // Standard property
            reasoningTokens: usage?.reasoningTokens,
            finishReason,
          };

          logger.debug(`üìä [CHAT-API] Step Usage (${stepType || 'unknown'}):`, stepUsageInfo);
        }
      },
    });

    logger.debug("üîç [CHAT-API] streamText returned, calling toUIMessageStreamResponse...");
    const response = result.toUIMessageStreamResponse();
    logger.debug("üîç [CHAT-API] toUIMessageStreamResponse succeeded");
    return response;

  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);

    // Detect timeout errors
    const isTimeout =
      errorMessage.includes('timeout') ||
      errorMessage.includes('TIMEOUT') ||
      errorMessage.includes('Function execution exceeded') ||
      errorMessage.includes('Execution timeout') ||
      (error && typeof error === 'object' && 'code' in error && error.code === 'TIMEOUT');

    if (isTimeout) {
      logger.error("‚è±Ô∏è [CHAT-API] Request timed out after 30 seconds", {
        errorMessage,
        workspaceId,
      });

      return new Response(JSON.stringify({
        error: "Request timeout",
        message: "The request took too long to process (exceeded 30 seconds). This can happen with complex queries that require multiple tool calls or extensive processing. Please try breaking your question into smaller parts or simplifying your request.",
        code: "TIMEOUT",
      }), {
        status: 504,
        headers: { "Content-Type": "application/json" },
      });
    }

    // Log other errors
    logger.error("‚ùå [CHAT-API] Error processing request", {
      errorMessage,
      errorStack: error instanceof Error ? error.stack : undefined,
      workspaceId,
    });

    return new Response(JSON.stringify({
      error: "Internal server error",
      message: "An unexpected error occurred while processing your request. Please try again.",
      details: process.env.NODE_ENV === 'development' ? errorMessage : undefined,
      code: "INTERNAL_ERROR",
    }), {
      status: 500,
      headers: { "Content-Type": "application/json" },
    });
  }
}
